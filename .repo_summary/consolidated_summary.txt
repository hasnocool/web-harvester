Here's a summary of the project:

**1. Project Name:** Web Harvester
**2. Short Description:** A GUI-based web crawler application that harvests data from websites according to specified parameters.
**3. Overall Description:** The Web Harvester is an interactive tool designed for users to extract website content, navigate hyperlinks, and collect specific data based on user-defined criteria, such as domain URL, depth of crawling, and filters. It utilizes a separate thread to manage the crawling process, ensuring smooth interaction with the GUI. This project showcases my ability to combine web development, multithreading, and GUI design to create an efficient and user-friendly application.
**4. Main Purpose:** I built this to provide users with an easy-to-use interface for collecting website data while maintaining control over the crawl parameters and output results.
**5. Key Technologies:**
	* Python
	* Qt Designer (for GUI creation)
	* Multithreading (using QThread and signals/slots)
**6. Unique Features:**
	- A user-friendly GUI with intuitive input fields for domain URL, depth, filters, and output file name.
	- Real-time console output displaying crawling progress, warnings, or errors.
**7. Future Improvements:**
	+ Implementing a more sophisticated filtering system that allows users to specify advanced filtering rules.
	+ Enhancing the application's multithreading capabilities for improved performance and parallelization of crawls.
**8. Personal Notes:** While this project focused on creating an efficient web harvester, I'm excited about exploring ways to improve its stability and scalability in the face of complex website structures or high-traffic domains.
**9. GitHub Tags:** `web-crawler`, `gui-application`, `multithreading`, `python-project`, `qt-designer`, `data-harvesting`

# Extractable Variables
SHORT_DESCRIPTION = "A GUI-based web crawler application that harvests data from websites according to specified parameters. 3. Overall Description: The Web Harvester is an interactive tool designed for users to extract website content, navigate hyperlinks, and collect specific data based on user-defined criteria, such as domain URL, depth of crawling, and filters. It utilizes a separate thread to manage the crawling process, ensuring smooth interaction with the GUI. This project showcases my ability to combine web development, multithreading, and GUI design to create an efficient and user-friendly application. 4. Main Purpose: I built this to provide users with an easy-to-use interface for collecting website data while maintaining control over the crawl parameters and output results. 5. Key Technologies: Python Qt Designer (for GUI creation) Multithreading (using QThread and signals/slots) 6. Unique Features: - A user-friendly GUI with intuitive input fields for domain URL, depth, filters, and output file name. - Real-time console output displaying crawling progress, warnings, or errors. 7. Future Improvements: + Implementing a more sophisticated filtering system that allows users to specify advanced filtering rules. + Enhancing the application's multithreading capabilities for improved performance and parallelization of crawls. 8. Personal Notes: While this project focused on creating an efficient web harvester, I'm excited about exploring ways to improve its stability and scalability in the face of complex website structures or high-traffic domains. 9. GitHub Tags: `web-crawler`, `gui-application`, `multithreading`, `python-project`, `qt-designer`, `data-harvesting`"
OVERALL_DESCRIPTION = "The Web Harvester is an interactive tool designed for users to extract website content, navigate hyperlinks, and collect specific data based on user-defined criteria, such as domain URL, depth of crawling, and filters. It utilizes a separate thread to manage the crawling process, ensuring smooth interaction with the GUI. This project showcases my ability to combine web development, multithreading, and GUI design to create an efficient and user-friendly application. 4. Main Purpose: I built this to provide users with an easy-to-use interface for collecting website data while maintaining control over the crawl parameters and output results. 5. Key Technologies: Python Qt Designer (for GUI creation) Multithreading (using QThread and signals/slots) 6. Unique Features: - A user-friendly GUI with intuitive input fields for domain URL, depth, filters, and output file name. - Real-time console output displaying crawling progress, warnings, or errors. 7. Future Improvements: + Implementing a more sophisticated filtering system that allows users to specify advanced filtering rules. + Enhancing the application's multithreading capabilities for improved performance and parallelization of crawls. 8. Personal Notes: While this project focused on creating an efficient web harvester, I'm excited about exploring ways to improve its stability and scalability in the face of complex website structures or high-traffic domains. 9. GitHub Tags: `web-crawler`, `gui-application`, `multithreading`, `python-project`, `qt-designer`, `data-harvesting`"
GITHUB_TAGS = "`web-crawler`, `gui-application`, `multithreading`, `python-project`, `qt-designer`, `data-harvesting`"
